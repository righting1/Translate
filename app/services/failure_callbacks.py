#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼‚æ­¥ä»»åŠ¡å¤±è´¥å›è°ƒå‡½æ•°é›†åˆ
æä¾›å„ç§å¸¸ç”¨çš„å¤±è´¥å¤„ç†å›è°ƒå‡½æ•°
"""
import logging
import json
import os
from datetime import datetime
from typing import Dict, Any
from pathlib import Path

logger = logging.getLogger(__name__)


async def log_failure_callback(failure_data: Dict[str, Any]):
    """è®°å½•å¤±è´¥ä¿¡æ¯åˆ°æ—¥å¿—çš„å›è°ƒå‡½æ•°"""
    logger.error(
        f"Task {failure_data['task_id']} ({failure_data['task_type']}) failed: "
        f"{failure_data['error_message']} "
        f"(Retry {failure_data['retry_count']}/{failure_data['max_retries']})"
    )


async def save_failure_to_file_callback(failure_data: Dict[str, Any]):
    """å°†å¤±è´¥ä¿¡æ¯ä¿å­˜åˆ°æ–‡ä»¶çš„å›è°ƒå‡½æ•°"""
    try:
        # åˆ›å»ºå¤±è´¥æ—¥å¿—ç›®å½•
        failure_log_dir = Path("logs/failures")
        failure_log_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"task_failure_{failure_data['task_id']}_{timestamp}.json"
        filepath = failure_log_dir / filename
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            **failure_data,
            "created_at": failure_data['created_at'].isoformat() if hasattr(failure_data['created_at'], 'isoformat') else str(failure_data['created_at']),
            "failed_at": failure_data['failed_at'].isoformat() if hasattr(failure_data['failed_at'], 'isoformat') else str(failure_data['failed_at'])
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Saved failure details to {filepath}")
        
    except Exception as e:
        logger.error(f"Failed to save failure details to file: {e}")


async def send_notification_callback(failure_data: Dict[str, Any]):
    """å‘é€é€šçŸ¥çš„å›è°ƒå‡½æ•°ï¼ˆç¤ºä¾‹ï¼‰"""
    try:
        # è¿™é‡Œå¯ä»¥é›†æˆå„ç§é€šçŸ¥æœåŠ¡ï¼Œå¦‚é‚®ä»¶ã€Slackã€é’‰é’‰ç­‰
        notification_message = (
            f"ğŸš¨ å¼‚æ­¥ä»»åŠ¡å¤±è´¥é€šçŸ¥\n"
            f"ä»»åŠ¡ID: {failure_data['task_id']}\n"
            f"ä»»åŠ¡ç±»å‹: {failure_data['task_type']}\n"
            f"é”™è¯¯ä¿¡æ¯: {failure_data['error_message']}\n"
            f"é‡è¯•æ¬¡æ•°: {failure_data['retry_count']}/{failure_data['max_retries']}\n"
            f"å¤±è´¥æ—¶é—´: {failure_data['failed_at']}"
        )
        
        # ç¤ºä¾‹ï¼šä¿å­˜é€šçŸ¥åˆ°æ–‡ä»¶ï¼ˆå®é™…ä½¿ç”¨æ—¶å¯ä»¥æ›¿æ¢ä¸ºçœŸå®çš„é€šçŸ¥æœåŠ¡ï¼‰
        notification_file = Path("logs/notifications.txt")
        notification_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(notification_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().isoformat()} - {notification_message}\n\n")
        
        logger.info(f"Sent failure notification for task {failure_data['task_id']}")
        
    except Exception as e:
        logger.error(f"Failed to send notification: {e}")


async def retry_with_different_model_callback(failure_data: Dict[str, Any]):
    """ä½¿ç”¨ä¸åŒæ¨¡å‹é‡è¯•çš„å›è°ƒå‡½æ•°"""
    try:
        # è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å›è°ƒï¼Œå±•ç¤ºå¦‚ä½•åœ¨å¤±è´¥æ—¶å°è¯•ä½¿ç”¨ä¸åŒçš„æ¨¡å‹
        from .async_task_manager import task_manager, TaskType
        
        # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šä¸”é”™è¯¯ä¸æ¨¡å‹ç›¸å…³
        if (failure_data['retry_count'] < failure_data['max_retries'] and 
            any(keyword in failure_data['error_message'].lower() for keyword in 
                ['model', 'api', 'token', 'rate limit'])):
            
            # æ¨¡å‹å¤‡é€‰åˆ—è¡¨
            model_alternatives = ['openai', 'dashscope', 'zhipuai']
            current_model = failure_data.get('model_name', 'openai')
            
            # é€‰æ‹©ä¸åŒçš„æ¨¡å‹
            next_model = None
            for model in model_alternatives:
                if model != current_model:
                    next_model = model
                    break
            
            if next_model:
                logger.info(f"Attempting to retry task {failure_data['task_id']} with model {next_model}")
                
                # åˆ›å»ºæ–°ä»»åŠ¡ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ï¼ˆè¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…å®ç°éœ€è¦æ›´ä»”ç»†çš„è®¾è®¡ï¼‰
                # task_manager.create_task(
                #     task_type=TaskType(failure_data['task_type']),
                #     input_data=failure_data['input_data'],
                #     model_name=next_model,
                #     max_retries=1  # é™åˆ¶é‡è¯•æ¬¡æ•°é¿å…æ— é™é€’å½’
                # )
        
    except Exception as e:
        logger.error(f"Failed to retry with different model: {e}")


async def cleanup_failed_task_data_callback(failure_data: Dict[str, Any]):
    """æ¸…ç†å¤±è´¥ä»»åŠ¡æ•°æ®çš„å›è°ƒå‡½æ•°"""
    try:
        # å¦‚æœä»»åŠ¡å½»åº•å¤±è´¥ï¼ˆå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰ï¼Œå¯ä»¥è¿›è¡Œä¸€äº›æ¸…ç†å·¥ä½œ
        if failure_data['retry_count'] >= failure_data['max_retries']:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_dir = Path(f"temp/task_{failure_data['task_id']}")
            if temp_dir.exists():
                import shutil
                shutil.rmtree(temp_dir)
                logger.info(f"Cleaned up temporary files for failed task {failure_data['task_id']}")
            
            # è®°å½•å¤±è´¥ç»Ÿè®¡
            stats_file = Path("logs/failure_stats.json")
            stats_file.parent.mkdir(parents=True, exist_ok=True)
            
            stats = {}
            if stats_file.exists():
                with open(stats_file, 'r', encoding='utf-8') as f:
                    stats = json.load(f)
            
            task_type = failure_data['task_type']
            if task_type not in stats:
                stats[task_type] = {"total_failures": 0, "last_failure": None}
            
            stats[task_type]["total_failures"] += 1
            stats[task_type]["last_failure"] = failure_data['failed_at'].isoformat() if hasattr(failure_data['failed_at'], 'isoformat') else str(failure_data['failed_at'])
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
                
    except Exception as e:
        logger.error(f"Failed to cleanup task data: {e}")


# é¢„å®šä¹‰çš„å›è°ƒå‡½æ•°åˆ—è¡¨
DEFAULT_FAILURE_CALLBACKS = [
    log_failure_callback,
    save_failure_to_file_callback,
    # send_notification_callback,  # å¯é€‰å¯ç”¨
    # retry_with_different_model_callback,  # å¯é€‰å¯ç”¨
    cleanup_failed_task_data_callback,
]


def register_default_callbacks(task_manager):
    """æ³¨å†Œé»˜è®¤çš„å¤±è´¥å›è°ƒå‡½æ•°"""
    for callback in DEFAULT_FAILURE_CALLBACKS:
        task_manager.add_global_failure_callback(callback)
    logger.info(f"Registered {len(DEFAULT_FAILURE_CALLBACKS)} default failure callbacks")